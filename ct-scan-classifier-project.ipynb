{"cells":[{"cell_type":"markdown","metadata":{},"source":["# COVID-19 CT Image Classification Using PyTorch\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Steps\n","\n","1. Data Preparation\n","2. Initial Model Development\n","3. Model Performance Using Data Augmentation\n","4. Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:09.051404Z","iopub.status.busy":"2024-08-27T17:10:09.050932Z","iopub.status.idle":"2024-08-27T17:10:09.062497Z","shell.execute_reply":"2024-08-27T17:10:09.060563Z","shell.execute_reply.started":"2024-08-27T17:10:09.051357Z"},"trusted":true},"outputs":[],"source":["import os  \n","import glob\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","import PIL \n","import numpy as np\n","import matplotlib.pyplot as plt \n","\n","import torch\n","import torch.nn as nn\n","# from torchinfo import summary \n","\n","import torch.optim as optim\n","from IPython.display import Image\n","from torch.utils.data import DataLoader, Dataset\n","\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import transforms\n","\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:09.711507Z","iopub.status.busy":"2024-08-27T17:10:09.711120Z","iopub.status.idle":"2024-08-27T17:10:09.724681Z","shell.execute_reply":"2024-08-27T17:10:09.722764Z","shell.execute_reply.started":"2024-08-27T17:10:09.711469Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device "]},{"cell_type":"markdown","metadata":{},"source":["Set Random Seed for reproducability"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:11.910514Z","iopub.status.busy":"2024-08-27T17:10:11.910022Z","iopub.status.idle":"2024-08-27T17:10:11.926154Z","shell.execute_reply":"2024-08-27T17:10:11.924568Z","shell.execute_reply.started":"2024-08-27T17:10:11.910457Z"},"trusted":true},"outputs":[],"source":["random_seed = 124\n","np.random.seed(random_seed)\n","\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 Generating Labels and Creating Sets for Modeling\n","\n","Extract file links for both postive and negative images and split the dataset into train, validation, and test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:13.841230Z","iopub.status.busy":"2024-08-27T17:10:13.840834Z","iopub.status.idle":"2024-08-27T17:10:14.072193Z","shell.execute_reply":"2024-08-27T17:10:14.070687Z","shell.execute_reply.started":"2024-08-27T17:10:13.841186Z"},"trusted":true},"outputs":[],"source":["path = '/kaggle/input/covidct/'\n","\n","pos_files = glob.glob(os.path.join(path, \"CT_COVID\",'*.*'))\n","neg_files = glob.glob(os.path.join(path, 'CT_NonCOVID','*.*'))\n","\n","images = pos_files + neg_files\n","labels = np.array([1]*len(pos_files)+[0]*len(neg_files))\n","\n","images_tv, images_test, y_tv, y_test  = train_test_split(images, labels, shuffle=True, test_size=0.2, random_state=123)\n","images_train, images_val, y_train, y_val  = train_test_split(images_tv, y_tv, shuffle=True, test_size=0.25, random_state=123)"]},{"cell_type":"markdown","metadata":{},"source":["From the plot below, observe that we have a balanced yet very small dataset at our disposal. Not ideal, but never the end of the road. Let's do our best to make the most out of what we have before we collect more data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:16.098530Z","iopub.status.busy":"2024-08-27T17:10:16.095957Z","iopub.status.idle":"2024-08-27T17:10:16.482174Z","shell.execute_reply":"2024-08-27T17:10:16.479707Z","shell.execute_reply.started":"2024-08-27T17:10:16.098400Z"},"trusted":true},"outputs":[],"source":["num_pos, num_neg = len(pos_files), len(neg_files)\n","\n","plt.title('Distribution of labels')\n","plt.bar(['Positive', 'Negative'], [num_pos, num_neg])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Let's take a look at some of the images!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:17.806461Z","iopub.status.busy":"2024-08-27T17:10:17.805735Z","iopub.status.idle":"2024-08-27T17:10:17.858420Z","shell.execute_reply":"2024-08-27T17:10:17.856852Z","shell.execute_reply.started":"2024-08-27T17:10:17.806383Z"},"trusted":true},"outputs":[],"source":["Image(images_train[1])\n","Image(images_train[15])\n","Image(images_train[66])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:19.503094Z","iopub.status.busy":"2024-08-27T17:10:19.502648Z","iopub.status.idle":"2024-08-27T17:10:20.729647Z","shell.execute_reply":"2024-08-27T17:10:20.727777Z","shell.execute_reply.started":"2024-08-27T17:10:19.502972Z"},"trusted":true},"outputs":[],"source":["im = [cv2.imread(images_train[i]) for i in range(6)]\n","\n","fig,ax = plt.subplots(ncols=6, figsize=(18,6))\n","for i in range(len(im)):\n","    ax[i].imshow(im[i],cmap='gray')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:10:25.286515Z","iopub.status.busy":"2024-08-27T17:10:25.286101Z","iopub.status.idle":"2024-08-27T17:10:25.296030Z","shell.execute_reply":"2024-08-27T17:10:25.293570Z","shell.execute_reply.started":"2024-08-27T17:10:25.286474Z"},"trusted":true},"outputs":[],"source":["print(f'Number of samples in each set (train, val, test): {len(y_train), len(y_val), len(y_test)}')\n","\n","print(f'Number of positive samples in each set: {y_train.sum(), y_val.sum(), y_test.sum()}')"]},{"cell_type":"markdown","metadata":{},"source":["### Dataset Class\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:12:12.338818Z","iopub.status.busy":"2024-08-27T17:12:12.338475Z","iopub.status.idle":"2024-08-27T17:12:12.355334Z","shell.execute_reply":"2024-08-27T17:12:12.353537Z","shell.execute_reply.started":"2024-08-27T17:12:12.338774Z"},"trusted":true},"outputs":[],"source":["class CT_Dataset(Dataset):\n","    def __init__(self, img_path, img_labels, img_transforms=None, grayscale=True):\n","        self.img_path = img_path\n","        self.img_labels = torch.Tensor(img_labels)\n","        if (img_transforms is None) & (grayscale == True):\n","            self.transforms = transforms.Compose([transforms.Grayscale(),\n","                                                  transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        elif grayscale == False:\n","            self.transforms = transforms.Compose([transforms.Resize((250, 250)),\n","                                                  transforms.ToTensor()])\n","        else:\n","            self.transforms = img_transforms\n","    \n","    def __getitem__(self, index):\n","        # load image\n","        cur_path = self.img_path[index]\n","        cur_img = PIL.Image.open(cur_path).convert('RGB')\n","        cur_img = self.transforms(cur_img)\n","\n","        return cur_img, self.img_labels[index]\n","    \n","    def __len__(self):\n","        return len(self.img_path)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Model Development"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Network Configuration\n","\n","The model used for this exercise has several key layers:\n","\n","\n","*   Conv2D $\\rightarrow$ Batch Normalization $\\rightarrow$ ReLU Activation $\\rightarrow$ AvgPooling2D\n","  * Output Channels: 64\n","  * Filter Size: 3x3\n","  * AvgPooling Filter Size: 2x2\n","*   Conv2D $\\rightarrow$ Batch Normalization $\\rightarrow$ ReLU Activation $\\rightarrow$ AvgPooling2D\n","  * Output Channels: 128\n","  * Filter Size: 3x3\n","  * AvgPooling Filter Size: 2x2\n","*   Conv2D $\\rightarrow$ Batch Normalization $\\rightarrow$ ReLU Activation $\\rightarrow$ AvgPooling2D\n","  * Output Channels: 256\n","  * Filter Size: 3x3\n","  * AvgPooling Filter Size: 2x2\n","*   Conv2D $\\rightarrow$ Batch Normalization $\\rightarrow$ ReLU Activation $\\rightarrow$ AvgPooling2D\n","  * Output Channels: 512\n","  * Filter Size: 3x3\n","  * AvgPooling Filter Size: 2x2\n","*   Conv2D $\\rightarrow$ Batch Normalization $\\rightarrow$ ReLU Activation $\\rightarrow$ AvgPooling2D $\\rightarrow$ Flatten\n","  * Output Channels: 512\n","  * Filter Size: 3x3\n","  * AvgPooling Filter Size: 2x2\n","  * Output Shape (After Flatten): (Batch Size, 1600)\n","\n","After the series of convolutions, we pass the parameters through a series of Dropout, Linear, and ReLU layers and produce an output of shape (Batch Size, 1)\n","*   Dropout $\\rightarrow$ Linear $\\rightarrow$ ReLU Activation $\\rightarrow$ Dropout $\\rightarrow$ Linear $\\rightarrow$ ReLU Activation $\\rightarrow$ Linear $\\rightarrow$ ReLU Activation $\\rightarrow$ Linear\n","  * Dropout Ratio: 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:12:12.360964Z","iopub.status.busy":"2024-08-27T17:12:12.358094Z","iopub.status.idle":"2024-08-27T17:12:12.384564Z","shell.execute_reply":"2024-08-27T17:12:12.382994Z","shell.execute_reply.started":"2024-08-27T17:12:12.360888Z"},"trusted":true},"outputs":[],"source":["# define CNN mode\n","class Convnet(nn.Module):\n","    \n","    def __init__(self, dropout=0.5):\n","        super(Convnet, self).__init__()\n","        self.convnet = nn.Sequential(\n","          # input (num_batch, 1, 250, 250)\n","          nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3),  # (num_batch, 64, 248, 248)\n","          nn.BatchNorm2d(64),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2),  # (num_batch, 64, 124, 124)\n","\n","          nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3), # (num_batch, 128, 122, 122)\n","          nn.BatchNorm2d(128),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2),  # (num_batch, 128, 61, 61)\n","\n","          nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3), # (num_batch, 256, 59, 59)\n","          nn.BatchNorm2d(256),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2),  # (num_batch, 256, 29, 29)\n","\n","          nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3), # (num_batch, 128, 27, 27)\n","          nn.BatchNorm2d(512),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2),  # (num_batch, 128, 13, 13)\n","\n","          nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3), # (num_batch, 64, 11, 11)\n","          nn.BatchNorm2d(512),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2),  # (num_batch, 64, 5, 5)\n","          nn.Flatten() # (num_batch, 1600)\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(dropout),  # Dropout before first linear layer since it has a large number of trainable parameters\n","            nn.Linear(in_features= 12800, out_features=512),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(in_features=512, out_features=256),\n","            nn.ReLU(),\n","            nn.Linear(in_features=256, out_features=128),\n","            nn.ReLU(),\n","            nn.Linear(in_features=128, out_features=1)\n","        )\n","    def forward(self, x):\n","        x = self.convnet(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["#### Print model summary to  visualize network structure"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:12:13.359752Z","iopub.status.busy":"2024-08-27T17:12:13.359387Z","iopub.status.idle":"2024-08-27T17:12:13.540531Z","shell.execute_reply":"2024-08-27T17:12:13.539072Z","shell.execute_reply.started":"2024-08-27T17:12:13.359711Z"},"trusted":true},"outputs":[],"source":["vision_model = Convnet()\n","summary(vision_model, (32, 1, 250, 250))"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Model Training Procedure\n","The training sequence used for our CNN model is summarized below:\n","\n","\n","*   **Loss Function**: *Binary Cross Entropy w/ Logistic Loss*\n","*   **Optimizer**: *Adam Optimization*\n","  * To fight overfitting the following methods were used:\n","      * **L2 Regularization**: Weight regularization using L2 Norm\n","      * **Learning Schedule**: *Decrease the learning rate* over a set period of epochs\n","\n","Parameters used for training:\n","\n","\n","*   **Initial Learning Rate**: 0.0002\n","*   Learning Schedule: \n","  * **Gamma**: 0.5\n","  * **Patience**: 7 epochs\n","*   **Number of Epochs**: 35\n","*   **Batch Size**: 32\n","*   **L2 Weight Decay**: 0.09\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:12:22.869328Z","iopub.status.busy":"2024-08-27T17:12:22.868931Z","iopub.status.idle":"2024-08-27T17:12:22.898242Z","shell.execute_reply":"2024-08-27T17:12:22.896709Z","shell.execute_reply.started":"2024-08-27T17:12:22.869286Z"},"trusted":true},"outputs":[],"source":["# define training function\n","\n","def train_model(model, train_dataset, val_dataset, test_dataset, device, \n","                lr=0.0001, epochs=30, batch_size=32, l2=0.00001, gamma=0.5,\n","                patience=7):\n","    model = model.to(device)\n","\n","    # construct dataloader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","    # history\n","    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n","\n","    # set up loss function and optimizer\n","    criterion = nn.BCEWithLogitsLoss()  \n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2)  # pass in the parameters to be updated and learning rate\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=patience, gamma=gamma)\n","\n","    # Training Loop\n","    print(\"Training Start:\")\n","    for epoch in range(epochs):\n","        model.train()  # start to train the model, activate training behavior\n","\n","        train_loss = 0\n","        train_acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        for i, (images, labels) in enumerate(train_loader):\n","            # reshape images\n","            images = images.to(device)  # reshape: from (128, 1, 28, 28) -> (128, 28 * 28) = (128, 284), move batch to device\n","            labels = labels.to(device)  # move to device\n","            # forward\n","            outputs = model(images).view(-1)  # forward\n","            pred = torch.sigmoid(outputs)\n","            pred = torch.round(pred)\n","    \n","            cur_train_loss = criterion(outputs, labels)  # loss\n","            cur_train_acc = (pred == labels).sum().item() / batch_size\n","\n","            # backward\n","            cur_train_loss.backward()   # run back propagation\n","            optimizer.step()            # optimizer update all model parameters\n","            optimizer.zero_grad()       # set gradient to zero, avoid gradient accumulating\n","\n","            # loss\n","            train_loss += cur_train_loss \n","            train_acc += cur_train_acc\n","        \n","        # valid\n","        model.eval()  # start to train the model, activate training behavior\n","        with torch.no_grad():  # tell pytorch not to update parameters\n","            for images, labels in val_loader:\n","                # calculate validation loss\n","                images = images.to(device)\n","                labels = labels.to(device)\n","\n","                outputs = model(images).view(-1)\n","\n","                # loss\n","                cur_valid_loss = criterion(outputs, labels)\n","                val_loss += cur_valid_loss\n","                # acc\n","                pred = torch.sigmoid(outputs)\n","                pred = torch.round(pred)\n","                val_acc += (pred == labels).sum().item() / batch_size\n","\n","        # learning schedule step\n","        scheduler.step()\n","\n","        # print training feedback\n","        train_loss = train_loss / len(train_loader)\n","        train_acc = train_acc / len(train_loader)\n","        val_loss = val_loss / len(val_loader)\n","        val_acc = val_acc / len(val_loader)\n","\n","        print(f\"Epoch:{epoch + 1} / {epochs}, lr: {optimizer.param_groups[0]['lr']:.5f} train loss:{train_loss:.5f}, train acc: {train_acc:.5f}, valid loss:{val_loss:.5f}, valid acc:{val_acc:.5f}\")\n","    \n","        # update history\n","        history['train_loss'].append(train_loss)\n","        history['train_acc'].append(train_acc)\n","        history['val_loss'].append(val_loss)\n","        history['val_acc'].append(val_acc)\n","    \n","    test_acc = 0\n","\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # calculate outputs by running images through the network\n","            outputs = model(images)\n","\n","            # the class with the highest energy is what we choose as prediction\n","            pred = torch.sigmoid(outputs)\n","            pred = torch.round(pred)\n","            test_acc += (pred == labels).sum().item()\n","\n","    print(f'Test Accuracy:  {(test_acc / len(test_loader))}')\n","\n","    return history"]},{"cell_type":"markdown","metadata":{},"source":["Process the datasets and train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-27T17:12:24.746364Z","iopub.status.busy":"2024-08-27T17:12:24.745986Z"},"trusted":true},"outputs":[],"source":["# Load the data\n","train_dataset = CT_Dataset(img_path=images_train, img_labels=y_train)\n","val_dataset = CT_Dataset(img_path=images_val, img_labels=y_val)\n","test_dataset = CT_Dataset(img_path=images_test, img_labels=y_test)\n","\n","# Train the CNN model\n","cnn_model = Convnet(dropout=0.5)\n","hist = train_model(cnn_model, train_dataset, val_dataset, test_dataset, device, lr=0.0002, batch_size=32, epochs=35, l2=0.09, patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.068612Z","iopub.status.idle":"2024-08-27T17:03:42.069314Z","shell.execute_reply":"2024-08-27T17:03:42.068961Z","shell.execute_reply.started":"2024-08-27T17:03:42.068929Z"},"trusted":true},"outputs":[],"source":["# plot training curves\n","epochs = range(1, len(hist['train_loss']) + 1)\n","\n","fig, ax = plt.subplots(1,2, figsize=(18,6))\n","ax[0].plot(epochs, hist['train_loss'], 'r-', label='Train')\n","ax[0].plot(epochs, hist['val_loss'], 'b-', label='Evaluation')\n","ax[0].set_title('Loss')\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss')\n","ax[0].legend()\n","\n","ax[1].plot(epochs, hist['train_acc'], 'r-', label='Train')\n","ax[1].plot(epochs, hist['val_acc'], 'b-', label='Evaluation')\n","ax[1].set_title('Accuracy')\n","ax[1].set_xlabel('Epochs')\n","ax[1].set_ylabel('Acc')\n","ax[1].legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Results For Initial Model\n","\n","The learning curves shown above show reasonable results.\n","\n","**Observations** \n","\n","\n","*   The model begins to overfit on the training data after 10 epochs\n","*   Training Accuracy generally reaches around 99\\% relatively quickly\n","* Validation accuracy stabilizes at around 80\\%.\n","* Training loss converges to near zero\n","* Validation loss converges around 0.4\n","* Accuracy on the test set is 88\\% -- a surprising result given the validation performance\n","\n","Overall, our first model achieved an accuracy of 88\\% for our hold out set. Given the size of our network and the lack of available data, these results are quite satisfying. With that being said, we cannot ignore the fact that our model overfits quite early in training. Since we achieve a near perfect score for training, I have no doubt we can continue to tune this model and achieve even better results on our hold-out set and bridge the gap between performance for training and validation.\n","\n","**Considerations to fight overfitting**\n","\n","\n","*   Add L1 Regularization\n","*   Data Augmentation (see next section)\n","*   Transfer Learning (see later sections)\n","*   More hyperparameter tuning"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Data Augmentation\n","\n","Data Augmentation is a technique used to either diversify a training set or add more samples to it. To augment an image is to apply specified transformation to the pixels of the image array. Examples of augmentations include rescaling, resizing, and translating the image to name a few. Implementing these augmentationss in PyTorch is quite straightforward. In this section we will apply augmentations on the entire dataset as well as a fraction of our data to generate \"new\" samples to add to our dataset and run our model to compare performance."]},{"cell_type":"markdown","metadata":{},"source":["#### Augmentations Used\n","* **Grayscale**\n","* **Resize** $\\rightarrow$ 250 x 250\n","* **RandomAffine**\n","  * **Translate**: Width $\\rightarrow$ 0.01, Height $\\rightarrow$ 0.001\n","  * **Image Scaling**: Width $\\rightarrow$ 1.2x, Height $\\rightarrow$ 1.2x\n","  * **Shear**: 0.9\n","* **RandomRotation**: 20 degrees\n","* **Convert Image to Tensor**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.071530Z","iopub.status.idle":"2024-08-27T17:03:42.072040Z","shell.execute_reply":"2024-08-27T17:03:42.071833Z","shell.execute_reply.started":"2024-08-27T17:03:42.071805Z"},"trusted":true},"outputs":[],"source":["img = PIL.Image.open(images_train[10])\n","\n","img_trans = transforms.Compose([transforms.Grayscale(),\n","                                transforms.RandomRotation(5),\n","                                transforms.Resize((250, 250)),\n","                                transforms.RandomAffine(degrees=0, scale=(1.1, 1.1), shear=0.9),\n","                                transforms.ToTensor()\n","                                ])\n","trans = img_trans(img)\n","\n","print('Before Transformation')\n","display(img)\n","print('\\nAfter Transformation')\n","display(transforms.ToPILImage()(trans))"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1 Data Augmentation Approach \\#1 -- Augmenting the entire Training Set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.074796Z","iopub.status.idle":"2024-08-27T17:03:42.075342Z","shell.execute_reply":"2024-08-27T17:03:42.075115Z","shell.execute_reply.started":"2024-08-27T17:03:42.075081Z"},"trusted":true},"outputs":[],"source":["train_dataset_full_aug = CT_Dataset(img_path=images_train, img_labels=y_train, img_transforms=img_trans)\n","val_dataset = CT_Dataset(img_path=images_val, img_labels=y_val)\n","test_dataset = CT_Dataset(img_path=images_test, img_labels=y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.076747Z","iopub.status.idle":"2024-08-27T17:03:42.077130Z","shell.execute_reply":"2024-08-27T17:03:42.076958Z","shell.execute_reply.started":"2024-08-27T17:03:42.076937Z"},"trusted":true},"outputs":[],"source":["# Train the CNN model\n","cnn_model = Convnet()\n","hist_full_aug = train_model(cnn_model, train_dataset_full_aug, val_dataset, \n","                            test_dataset, device, lr=0.0001, batch_size=32, epochs=35,\n","                            gamma=0.75, l2=0.09, patience=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.079319Z","iopub.status.idle":"2024-08-27T17:03:42.079765Z","shell.execute_reply":"2024-08-27T17:03:42.079577Z","shell.execute_reply.started":"2024-08-27T17:03:42.079549Z"},"trusted":true},"outputs":[],"source":["# plot training curves\n","epochs = range(1, len(hist_full_aug['train_loss']) + 1)\n","\n","fig, ax = plt.subplots(1,2, figsize=(20,6))\n","ax[0].plot(epochs, hist_full_aug['train_loss'], 'r-', label='Train')\n","ax[0].plot(epochs, hist_full_aug['val_loss'], 'b-', label='Evaluation')\n","ax[0].set_title('Loss')\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss')\n","ax[0].legend()\n","\n","ax[1].plot(epochs, hist_full_aug['train_acc'], 'r-', label='Train')\n","ax[1].plot(epochs, hist_full_aug['val_acc'], 'b-', label='Evaluation')\n","ax[1].set_title('Accuracy')\n","ax[1].set_xlabel('Epochs')\n","ax[1].set_ylabel('Acc')\n","ax[1].legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Results from Approach 1\n","\n","**Observations**\n","\n","*   Drop in overall accuracy for both training and validation sets\n","*   Test accuracy came out to be 78\\% -- a considerable drop compared to the initial model \n","* The drop in overall performance may suggest that perhaps lack of data could be a contributing factor rather than the diversity in available samples"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 Data Augmentation Approach \\#2 -- Concatenate Augmented Data to Original Dataset\n","In this approach, the aim is to see if adding augmented samples into our dataset can help fight overfitting. We know that our sample size is small, so perhaps adding variations of samples on top of our original data may allow our model to generalize better. In doing this, we also run the risk of increasing the bias of our model.\n","\n","\n","In the code below we will augment 60 images from the training set and 20 images from the validation set and concatenate them on the original data. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.081575Z","iopub.status.idle":"2024-08-27T17:03:42.082009Z","shell.execute_reply":"2024-08-27T17:03:42.081810Z","shell.execute_reply.started":"2024-08-27T17:03:42.081782Z"},"trusted":true},"outputs":[],"source":["train_dataset_og = CT_Dataset(img_path=images_train, img_labels=y_train)\n","train_dataset_aug = CT_Dataset(img_path=images_train[:60], img_labels=y_train[:60], img_transforms=img_trans)\n","train_dataset_fin = torch.utils.data.ConcatDataset([train_dataset_og,train_dataset_aug])\n","\n","val_dataset_og = CT_Dataset(img_path=images_val, img_labels=y_val)\n","val_dataset_aug = CT_Dataset(img_path=images_val[:20], img_labels=y_val[:25], img_transforms=img_trans)\n","val_dataset_fin = torch.utils.data.ConcatDataset([val_dataset_og, val_dataset_aug])\n","\n","test_dataset = CT_Dataset(img_path=images_test, img_labels=y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.084832Z","iopub.status.idle":"2024-08-27T17:03:42.085280Z","shell.execute_reply":"2024-08-27T17:03:42.085089Z","shell.execute_reply.started":"2024-08-27T17:03:42.085068Z"},"trusted":true},"outputs":[],"source":["print(len(train_dataset_fin))\n","print(len(val_dataset_fin))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.087731Z","iopub.status.idle":"2024-08-27T17:03:42.088417Z","shell.execute_reply":"2024-08-27T17:03:42.088212Z","shell.execute_reply.started":"2024-08-27T17:03:42.088177Z"},"trusted":true},"outputs":[],"source":["# Train the CNN model\n","cnn_model = Convnet(dropout=0.5)\n","hist_concat = train_model(cnn_model, train_dataset_fin, val_dataset_fin, test_dataset, device, lr=0.0001, l2=0.09, batch_size=32, epochs=75)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.090254Z","iopub.status.idle":"2024-08-27T17:03:42.090700Z","shell.execute_reply":"2024-08-27T17:03:42.090516Z","shell.execute_reply.started":"2024-08-27T17:03:42.090490Z"},"trusted":true},"outputs":[],"source":["# plot training curves\n","epochs = range(1, len(hist_concat['train_loss']) + 1)\n","\n","fig, ax = plt.subplots(1,2, figsize=(20,6))\n","ax[0].plot(epochs, hist_concat['train_loss'], 'r-', label='Train')\n","ax[0].plot(epochs, hist_concat['val_loss'], 'b-', label='Evaluation')\n","ax[0].set_title('Loss')\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss')\n","ax[0].legend()\n","\n","\n","ax[1].plot(epochs, hist_concat['train_acc'], 'r-', label='Train')\n","ax[1].plot(epochs, hist_concat['val_acc'], 'b-', label='Evaluation')\n","ax[1].set_title('Accuracy')\n","ax[1].set_xlabel('Epochs')\n","ax[1].set_ylabel('Acc')\n","ax[1].legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Results from Approach 2 \n","**Observations**\n","\n","\n","*   Test Accuracy: 87\\%\n","*   Distinct gap between training and validation results remain as learning plateaus after 20 epochs\n","*   The model achieves the highest accuracy for the hold out set compared to the previous models\n","*   Further investigation is needed to reduce the gap between training in validation sets \n","*   It would be interesting to see how the model reacts to adding a greater portion of augmented samples on top of the original dataset"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Transfer Learning (VGG-16)\n","\n","In this section, we will use the VGG-16 model which is pretrained on Image-Net to leverage the pre-trained parameters for this particular classification task. To achieve this, we will load the vgg-16 model using the torchvision library and then freeze the parameters for the \"features\" portiion of the model. We will then create our own custom \"classifier\" sequence of dense layers to overwrite the pre-trained classifier parameters trained on Image-Net. In this way, we leverage the visual power of VGG-16 while still training the model to classify positive or negative instances of COVID-19 in CT imgaes."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.092891Z","iopub.status.idle":"2024-08-27T17:03:42.093317Z","shell.execute_reply":"2024-08-27T17:03:42.093123Z","shell.execute_reply.started":"2024-08-27T17:03:42.093095Z"},"trusted":true},"outputs":[],"source":["import torchvision.models as models\n","\n","VGG_model = models.vgg16(pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.095091Z","iopub.status.idle":"2024-08-27T17:03:42.095543Z","shell.execute_reply":"2024-08-27T17:03:42.095321Z","shell.execute_reply.started":"2024-08-27T17:03:42.095292Z"},"trusted":true},"outputs":[],"source":["print(VGG_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.098124Z","iopub.status.idle":"2024-08-27T17:03:42.098805Z","shell.execute_reply":"2024-08-27T17:03:42.098506Z","shell.execute_reply.started":"2024-08-27T17:03:42.098470Z"},"trusted":true},"outputs":[],"source":["VGG_model = models.vgg16(pretrained=True)\n","\n","for name, param in VGG_model.named_parameters():\n","    param.requires_grad = False\n","\n","# define out classifier\n","binary_classifier = nn.Sequential(\n","   nn.Linear(in_features=25088, out_features=2048),\n","   nn.ReLU(),\n","   nn.Linear(in_features=2048, out_features=1024),\n","   nn.ReLU(),\n","   nn.Linear(in_features=1024, out_features=512),\n","   nn.ReLU(),\n","   nn.Linear(in_features=512, out_features=1)\n",")\n","\n","# replace model class classifier attribute:\n","VGG_model.classifier = binary_classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.101538Z","iopub.status.idle":"2024-08-27T17:03:42.102209Z","shell.execute_reply":"2024-08-27T17:03:42.101892Z","shell.execute_reply.started":"2024-08-27T17:03:42.101860Z"},"trusted":true},"outputs":[],"source":["train_dataset = CT_Dataset(img_path=images_train, img_labels=y_train, grayscale=False)\n","val_dataset = CT_Dataset(img_path=images_val, img_labels=y_val, grayscale=False)\n","test_dataset = CT_Dataset(img_path=images_test, img_labels=y_test, grayscale=False)\n","\n","# Train the CNN model\n","hist = train_model(VGG_model, train_dataset, val_dataset, test_dataset, device, lr=0.0001, batch_size=32, epochs=20, l2=0.2\n","                   , patience=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-27T17:03:42.104048Z","iopub.status.idle":"2024-08-27T17:03:42.104674Z","shell.execute_reply":"2024-08-27T17:03:42.104367Z","shell.execute_reply.started":"2024-08-27T17:03:42.104316Z"},"trusted":true},"outputs":[],"source":["# plot training curves\n","epochs = range(1, len(hist['train_loss']) + 1)\n","\n","fig, ax = plt.subplots(1,2, figsize=(20,6))\n","ax[0].plot(epochs, hist['train_loss'], 'r-', label='Train')\n","ax[0].plot(epochs, hist['val_loss'], 'b-', label='Evaluation')\n","ax[0].set_title('Loss')\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Loss')\n","ax[0].legend()\n","\n","\n","ax[1].plot(epochs, hist['train_acc'], 'r-', label='Train')\n","ax[1].plot(epochs, hist['val_acc'], 'b-', label='Evaluation')\n","ax[1].set_title('Accuracy')\n","ax[1].set_xlabel('Epochs')\n","ax[1].set_ylabel('Acc')\n","ax[1].legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Results from Transfer Learning\n","\n","**Observations**:\n","\n","\n","\n","*   Learning curves remain stable, however the model overfits on the training set after 7 epochs\n","*   Training loss converges to nearly 0.1 while validation loss plateaus at around 0.4 \n","*   Validation accuracy peaks at 0.81 and converges to around 0.8 at the end of training\n","*   Results on the test set yield an accuracy of 84\\% which beats our initial model\n","\n","Overall, the use of transfer learning for image classification is quite beneficial. VGG-16 provided us with just as good results even though the convolutional layers were trained on a completely different dataset. This showcases the power of transfer learning as we freezed the weights for the convolutional layers for this task. "]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":584020,"sourceId":1069347,"sourceType":"datasetVersion"}],"dockerImageVersionId":30152,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
